<html>

<head>
<title>Lihong Li</title>
<meta name="author" content="Lihong Li">
<meta name="description" content="Personal Homepage">
<meta name="keywords" content="Artificial Intelligence, Machine Learning, Reinforcement Learning, Planning, Research, Rutgers, Yahoo!, Microsoft, Google">
<meta name="classification" content="Personal Homepage">
</head>

<body bgcolor="f7f7f7" text="black" link="blue" vlink="purple" alink="red">

<h1> <img src="../img/lihong-pro.jpg"> Lihong Li <img src="../img/chinese-name.jpg" height="25"></h1>

Research Scientist <br/>
Google Inc. <br/><br/>
lihongli.cs@gmail.com (for general academic work) <br/>
lihong@google.com (for Google related work) <br/>
747 Sixth Street South, Kirkland, WA, USA 98033<br/>
<p>

<p/><hr>

[<a href="../index.html#interests"><font face="Times New Roman" size="3">Interests</font></a><font face="Times New Roman" size="3">]
[<a href="../index.html#experiences"><font face="Times New Roman" size="3">Experiences</font></a><font face="Times New Roman" size="3">]
[</font><a href="../pubs.html" target="_self"><font face="Times New Roman" size="3">Publications</font></a><font face="Times New Roman" size="3">]
[<a href="../index.html#activities"><font face="Times New Roman" size="3">Professional Activities</font></a><font face="Times New Roman" size="3">]
[</font><a href="../index.html" target="_self"><font face="Times New Roman" size="3">Back to Home</font></a><font face="Times New Roman" size="3">]

<p/><hr>

<h2>Applications to Natural Language Processing (NLP)</h2>

How can we introduce decision making abilities to natural language-based systems?  Some of the these NLP applications such as conversational systems can naturally be modeled in a decision-theoretic framework and optimized by reinforcement learning.

<ul>

<li>J. Gao, M. Galley, and <b>L. Li</b>: Neural approaches to Conversational AI: Question answering, task-oriented dialogues and social chatbots.  Foundations and Trends in Information Retrieval.  In preparation.  [<a href="https://arxiv.org/abs/1809.08267">draft version</a>]

<li>D. Tang, X. Li, J. Gao, C. Wang, <b>L. Li</b>, and T. Jebara: Subgoal discovery for hierarchical dialogue policy learning.  In <i>the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, 2018. [<a href="papers/tang18subgoal.pdf">PDF</a>]

<li>Z. Lipton, X. Li, J. Gao, <b>L. Li</b>, F. Ahmed, and L. Deng: Efficient dialogue policy learning with BBQ-networks.  In <i>the 32nd AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018. [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16189">link</a>]

<li>J. Chen, C. Wang, L. Xiao, J. He, <b>L. Li</b>, and L. Deng: Q-LDA: Uncovering latent patterns in text-based sequential decision processes.  In <i>Advances in Neural Information Processing Systems 30 (NIPS)</i>, 2017.  [<a href="http://papers.nips.cc/paper/7083-q-lda-uncovering-latent-patterns-in-text-based-sequential-decision-processes">link</a>]

<li>B. Peng, X. Li, <b>L. Li</b>, J. Gao, A. Celikyilmaz, S. Lee, and K.-F. Wong: Composite task-completion dialogue system via hierarchical deep reinforcement learning.  In <i>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, 2017. [<a href="https://aclanthology.info/papers/D17-1237/d17-1237">link</a>]

<li>B. Dhingra, <b>L. Li</b>, X. Li, J. Gao, Y.-N. Chen, F. Ahmed, and L. Deng: Towards end-to-end reinforcement learning of dialogue agents for information access.  In <i>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, 2017. [<a href="https://doi.org/10.18653/v1/P17-1045">link</a>]

<li>X. Li, Z.C. Lipton, B. Dhingra, <b>L. Li</b>, J. Gao, Y.-N. Chen: A user simulator for task-completion dialogues.  MSR technical report, December 2016.

<li>J. He, M. Ostendorf, X. He, J. Chen, J. Gao, <b>L. Li</b>, and L. Deng: Deep reinforcement learning with a combinatorial action space for predicting and tracking popular discussion threads.  In <i>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, 2016. [<a href="http://www.aclweb.org/anthology/D16-1189">link</a>]

<li>J. He, J. Chen, X. He, J. Gao, <b>L. Li</b>, L. Deng, and M. Ostendorf: Deep reinforcement learning with a natural language action space.  In <i>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, 2016. [<a href="http://aclweb.org/anthology/P/P16/P16-1153.pdf">link</a>]

<li>J. He, J. Chen, X. He, J. Gao, <b>L. Li</b>, L. Deng, and M. Ostendorf: Deep reinforcement learning with an unbounded action space.  In <i>the International Conference on Learning Representations (ICLR), Workshop Track</i>, 2016.

<li><b>L. Li</b>, H. He, and J.D. Williams: Temporal supervised learning for inferring a dialog policy from example conversations.  In the <i>IEEE Spoken Language Technology Workshop (SLT)</i>, 2014.

<li><b>L. Li</b>, J.D. Williams, and S. Balakrishnan: Reinforcement learning for spoken dialog management using least-squares policy iteration and fast feature selection. In <i>the 10th Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>, 2009.

</ul>

</html>
